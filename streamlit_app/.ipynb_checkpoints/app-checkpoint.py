# import streamlit as st
# import requests
# import pandas as pd
# import plotly.express as px
# from st_aggrid import AgGrid, GridOptionsBuilder

# # --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
# st.set_page_config(page_title="IR System", page_icon="ğŸ”", layout="wide")

# # --- ØªÙ†Ø³ÙŠÙ‚ CSS Ù…Ø®ØµØµ ---
# st.markdown("""
#     <style>
# .main {
#     background-color: #e6ebe6; /* Ø±Ù…Ø§Ø¯ÙŠ Ø¯Ø§ÙØ¦ ÙØ§ØªØ­ */
#     font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
# }
# .title {
#     font-size: 36px;
#     text-align: center;
#     color: #276749; /* Ø£Ø®Ø¶Ø± Ø¯Ø§ÙƒÙ† */
#     font-weight: bold;
# }
# .subtitle {
#     font-size: 18px;
#     color: #444;
#     text-align: center;
#     margin-bottom: 30px;
# }
# .stButton>button {
#     background-color: #276749; /* Ø£Ø®Ø¶Ø± Ø¯Ø§ÙƒÙ† */
#     color: white;
#     font-weight: bold;
#     width: 100%;
#     border-radius: 6px;
#     padding: 10px;
# }
# .stTextInput>div>div>input {
#     font-size: 16px;
# }
# h2, h3, .stTextInput label {
#     color: #276749;
# }

# .stButton>button {
#     background-color: #3a9950;  /* Ø£Ø®Ø¶Ø± Ù…ØªÙˆØ³Ø· */
#     color: white;
#     font-weight: bold;
#     width: 100%;
#     border-radius: 6px;
#     padding: 10px;
#     border: none;
#     transition: background-color 0.3s ease;
# }
# .stButton>button:hover {
#     background-color: #2a6f34;  /* Ø£Ø®Ø¶Ø± Ø£ØºÙ…Ù‚ Ø¹Ù†Ø¯ Ø§Ù„ØªÙ…Ø±ÙŠØ± */
# }
# /* ØªØ­Ø³ÙŠÙ† Ù„ÙˆÙ† Ø®Ø·ÙˆØ· Ø§Ù„Ø¬Ø¯ÙˆÙ„ */
# .ag-theme-balham {
#     --ag-border-color: #d1d5db;
#     --ag-row-hover-color: #e6f0ea;
# }
#     </style>
# """, unsafe_allow_html=True)

# st.markdown("<div class='title'>ğŸ” Information Retrieval System</div>", unsafe_allow_html=True)
# st.markdown("---")

# # --- Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ ---
# with st.sidebar:
#     st.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø­Ø«")
#     dataset = st.selectbox("ğŸ“ Ø§Ø®ØªØ± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", ["trec_tot", "antique"])
#     method = st.selectbox("ğŸ“Œ Ù†ÙˆØ¹ Ø§Ù„ØªÙ…Ø«ÙŠÙ„", ["tfidf", "embedding", "hybrid"])
#     top_k = st.slider("ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", min_value=1, max_value=20, value=5)
#     save_results = st.checkbox("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ØŸ")

# # --- Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ---
# st.subheader("ğŸ“ Ø£Ø¯Ø®Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ùƒ")
# query_text = st.text_input("", placeholder="Ù…Ø«Ø§Ù„: what is artificial intelligence?")

# # --- ØªØ¹ÙŠÙŠÙ† Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø¨ÙˆØ±Øª ---
# base_urls = {
#     "tfidf": "http://127.0.0.1:8001",
#     "embedding": "http://127.0.0.1:8002",
#     "hybrid": "http://127.0.0.1:8003",
# }

# endpoint_map = {
#     "tfidf": "/query-match",
#     "embedding": "/query-embedding",
#     "hybrid": "/query-hybrid"
# }

# # Ø®Ø¯Ù…Ø© ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ù„Ù‰ Ø¨ÙˆØ±Øª Ù…Ù†ÙØµÙ„
# refine_base_url = "http://127.0.0.1:8000"

# # --- ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø« ---
# if st.button("ğŸš€ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø«"):
#     if not query_text.strip():
#         st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø£ÙˆÙ„Ø§Ù‹.")
#     else:
#         with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¥Ù„Ù‰ Ø§Ù„Ø®Ø¯Ù…Ø©..."):
#             base_url = base_urls[method]
#             endpoint = endpoint_map[method]
#             payload = {
#                 "query": query_text,
#                 "top_k": top_k
#             }

#             try:
#                 response = requests.post(f"{base_url}{endpoint}?dataset={dataset}", json=payload)

#                 if response.status_code == 200:
#                     data = response.json()
#                     st.success("âœ… ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­")
#                     results_df = pd.DataFrame(data["results"])

#                     # âœ… Ø¹Ø±Ø¶ ØªÙØ§Ø¹Ù„ÙŠ Ù„Ù„Ù†ØªØ§Ø¦Ø¬
#                     st.subheader("ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
#                     gb = GridOptionsBuilder.from_dataframe(results_df)
#                     gb.configure_pagination()
#                     gb.configure_default_column(editable=False, groupable=True)
#                     AgGrid(results_df, gridOptions=gb.build(), theme="balham", height=350)

#                     # ğŸ“Š Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ
#                     if "score" in results_df.columns:
#                         st.subheader("ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨ÙŠÙ† Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ ÙˆØ§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…")
#                         fig = px.bar(results_df, x="doc_id", y="score", color="score",
#                                      labels={"doc_id": "Ù…Ø¹Ø±Ù‘Ù Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©", "score": "Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡"},
#                                      color_continuous_scale=px.colors.sequential.Tealgrn)
#                         st.plotly_chart(fig, use_container_width=True)

#                         st.markdown(
#                             """
#                             <div style='font-size:14px; color:#555; margin-top:-10px; margin-bottom:30px;'>
#                             Ù‡Ø°Ø§ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙŠÙˆØ¶Ø­ Ù…Ø¯Ù‰ ØªØ´Ø§Ø¨Ù‡ ÙƒÙ„ ÙˆØ«ÙŠÙ‚Ø© Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…Ø¯Ø®Ù„.  
#                             ÙƒÙ„ Ø¹Ù…ÙˆØ¯ ÙŠÙ…Ø«Ù„ ÙˆØ«ÙŠÙ‚Ø© ÙˆØ§Ø±ØªÙØ§Ø¹Ù‡ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ (ÙƒÙ„Ù…Ø§ Ø²Ø§Ø¯Øª Ø§Ù„Ø¯Ø±Ø¬Ø©ØŒ ÙƒØ§Ù†Øª Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø£ÙƒØ«Ø± Ù…Ù„Ø§Ø¦Ù…Ø© Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…).
#                             </div>
#                             """, unsafe_allow_html=True
#                         )

#                     # ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
#                     if save_results:
#                         filename = f"{dataset}_{method}_query_results.csv"
#                         results_df.to_csv(filename, index=False, encoding="utf-8")
#                         st.success(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: `{filename}`")

#                 else:
#                     st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:\n\n{response.text}")

#             except Exception as e:
#                 st.error(f"ğŸš« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…:\n\n{e}")

# # --- ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ---
# if st.button("ğŸ›  ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"):
#     if not query_text.strip():
#         st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø£ÙˆÙ„Ø§Ù‹.")
#     else:
#         with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù„Ù„ØªØ­Ø³ÙŠÙ†..."):
#             payload = {
#                 "query": query_text,
#                 "options": {
#                     "spelling_correction": True,
#                     "query_expansion": True,
#                     "query_suggestion": True
#                 }
#             }
#             try:
#                 response = requests.post(f"{refine_base_url}/refine-query?dataset={dataset}", json=payload)
#                 if response.status_code == 200:
#                     data = response.json()
#                     st.success("âœ… ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­")

#                     st.markdown(f"**Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø£ØµÙ„ÙŠ:** `{data['original_query']}`")

#                     if data.get("cleaned_query") and data["cleaned_query"] != data['original_query']:
#                         st.markdown(f"**Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠ:** `{data['cleaned_query']}`")

#                     if data.get("corrected_query") and data["corrected_query"] != data['original_query']:
#                         st.markdown(f"**Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø¹Ø¯ Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠ:** `{data['corrected_query']}`")
                        
#                     if data.get("expanded_query") and data["expanded_query"] != (data.get("corrected_query") or data['original_query']):
#                         st.markdown(f"**Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø¹Ø¯ Ø§Ù„ØªÙˆØ³ÙŠØ¹:** `{data['expanded_query']}`")

#                     if data.get("expanded_terms_added") and data["expanded_terms_added"] != (data.get("corrected_query") or data['original_query']):
#                         st.markdown(f"**Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¨Ø¯ÙŠÙ„:** `{data['expanded_terms_added']}`")

                        
#                     if data.get("suggestions"):
#                         st.markdown("**Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø£Ø®Ø±Ù‰:**")
#                         for s in data["suggestions"]:
#                             st.markdown(f"- {s}")

#                 else:
#                     st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:\n\n{response.text}")

#             except Exception as e:
#                 st.error(f"ğŸš« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…:\n\n{e}")
import streamlit as st
import requests
import pandas as pd

st.set_page_config(page_title="Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« - TF-IDF - Embedding - Hybrid", layout="wide")

API_BASE_URL = "http://localhost:8000"  # Ø¹Ø¯Ù„ Ø­Ø³Ø¨ Ø¹Ù†ÙˆØ§Ù† Ø³ÙŠØ±ÙØ± FastAPI Ù„Ø¯ÙŠÙƒ

def query_search(query: str, dataset: str, top_k: int, mode: str):
    """
    ÙŠØ³ØªØ¯Ø¹ÙŠ API Ø§Ù„Ø¨Ø­Ø« Ø­Ø³Ø¨ ÙˆØ¶Ø¹ Ø§Ù„Ø¨Ø­Ø« (tfidf, embedding, hybrid)
    """
    endpoint_map = {
        "tfidf": "/query_match",
        "embedding": "/query-embedding",
        "hybrid": "/query-hybrid"
    }
    url = API_BASE_URL + endpoint_map.get(mode, "/query_match")
    payload = {"query": query, "dataset": dataset, "top_k": top_k}
    try:
        response = requests.post(url, json=payload)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…: {e}")
        return None

def main():
    st.title("Ù…Ø­Ø±Ùƒ Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙˆØµ")
    st.write("")

    # Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    query_text = st.text_area("Ø§Ø¯Ø®Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø¨Ø­Ø«", height=80)

    col1, col2 = st.columns(2)
    with col1:
        dataset = st.selectbox(
            "Ø§Ø®ØªØ± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            options=["trec_tot", "antique"],
            index=0
        )
    with col2:
        top_k = st.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø±Ø§Ø¯ Ø¹Ø±Ø¶Ù‡Ø§", min_value=1, max_value=50, value=10, step=1)

    mode = st.radio(
        "Ù†ÙˆØ¹ Ø§Ù„ØªÙ…Ø«ÙŠÙ„:",
        options=["tfidf", "embedding", "hybrid"],
        index=0,
        horizontal=True
    )

    colb1, colb2 = st.columns(2)
    with colb1:
        search_btn = st.button("ğŸš€ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø«")
    with colb2:
        improve_btn = st.button("ğŸ›  ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…")

    # Ù…Ø³Ø§Ø­Ø© Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    results_placeholder = st.empty()
    cleaned_query_placeholder = st.empty()

    if search_btn:
        if not query_text.strip():
            st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø£ÙˆÙ„Ø§Ù‹.")
        else:
            with st.spinner("Ø¬Ø§Ø±ÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø«..."):
                data = query_search(query_text, dataset, top_k, mode)
                if data:
                    # Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ
                    cleaned_query = data.get("cleaned_query", "")
                    if cleaned_query:
                        cleaned_query_placeholder.markdown(f"**Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ:** {cleaned_query}")

                    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                    results = data.get("results", [])
                    if results:
                        df = pd.DataFrame(results)
                        # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¨Ø´ÙƒÙ„ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªÙ…Ø±ÙŠØ±
                        results_placeholder.dataframe(df)
                    else:
                        results_placeholder.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ø¹Ø±Ø¶.")
                else:
                    results_placeholder.error("ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ù† Ø§Ù„Ø®Ø§Ø¯Ù….")

    elif improve_btn:
        if not query_text.strip():
            st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø£ÙˆÙ„Ø§Ù‹ Ù„ØªØ­Ø³ÙŠÙ†Ù‡.")
        else:
            with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…..."):
                try:
                    refine_api_url = "http://localhost:8001/refine-query"  # Ø±Ø§Ø¨Ø· Ø®Ø¯Ù…Ø© ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…

                    payload = {
                        "query": query_text,
                        "options": {
                            "spelling_correction": True,
                            "query_expansion": True,
                            "query_suggestion": True
                        }
                    }
                    params = {"dataset": dataset}  # dataset ÙƒÙ€ query param

                    response = requests.post(refine_api_url, params=params, json=payload)
                    response.raise_for_status()
                    improved = response.json()

                    refined_query = improved.get("refined_query", "")
                    if refined_query:
                        st.success("âœ… ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­!")

                        with st.expander("ğŸ“„ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"):
                            st.markdown("**Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:**")
                            st.write(improved.get("original_query", ""))

                            st.markdown("**Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ:**")
                            st.write(improved.get("cleaned_query", ""))

                            if improved.get("corrected_query"):
                                st.markdown("**Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠ:**")
                                st.write(improved.get("corrected_query"))

                        with st.expander("ğŸ“ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØµØ­Ø­Ø©"):
                            corrected_terms = improved.get("corrected_terms_diff", [])
                            if corrected_terms:
                                for term in corrected_terms:
                                    st.markdown(f"- {term}")
                            else:
                                st.write("Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒÙ„Ù…Ø§Øª Ù…ØµØ­Ø­Ø©.")

                        with st.expander("â• Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙˆØ³Ø¹Ø©"):
                            expanded_terms = improved.get("expanded_terms_added", [])
                            if expanded_terms:
                                for term in expanded_terms:
                                    st.markdown(f"- {term}")
                            else:
                                st.write("Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒÙ„Ù…Ø§Øª Ù…ÙˆØ³Ø¹Ø©.")

                        with st.expander("ğŸ’¡ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¨Ø¯ÙŠÙ„Ø©"):
                            suggestions = improved.get("suggestions", [])
                            if suggestions:
                                for sug in suggestions:
                                    st.markdown(f"- {sug}")
                            else:
                                st.write("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª.")

                        st.markdown("**ğŸ” Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:**")
                        st.code(refined_query, language="text")
                    else:
                        st.info("Ù„Ù… ÙŠØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù….")

                except Exception as e:
                    st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… (8001): {e}")

if __name__ == "__main__":
    main()
